---
title: 'Visual Curiosity: Learning to Ask Questions to Learn Visual Recognition'
abstract: In an open-world setting, it is inevitable that an intelligent agent (e.g.,
  a robot) will encounter visual objects, attributes or relationships it does not
  recognize. In this work, we develop an agent empowered with visual curiosity, i.e.
  the ability to ask questions to an Oracle (e.g., human) about the contents in images
  (e.g., ‘What is the object on the left side of the red cube?’) and build visual
  recognition model based on the answers received (e.g., ‘Cylinder’). In order to
  do this, the agent must (1) understand what it recognizes and what it does not,
  (2) formulate a valid, unambiguous and informative ‘language’ query (a question)
  to ask the Oracle, (3) derive the parameters of visual classifiers from the Oracle
  response and (4) leverage the updated visual classifiers to ask more clarified questions.
  Specifically, we propose a novel framework and formulate the learning of visual
  curiosity as a reinforcement learning problem. In this framework, all components
  of our agent – visual recognition module (to see), question generation policy (to
  ask), answer digestion module (to understand) and graph memory module (to memorize)
  – are learned entirely end-to-end to maximize the reward derived from the scene
  graph obtained by the agent as a consequence of the dialog with the Oracle. Importantly,
  the question generation policy is disentangled from the visual recognition system
  and specifics of the ‘environment’ (scenes). Consequently, we demonstrate a sort
  of ‘double’ generalization – our question generation policy generalizes to new environments
  and a new pair of eyes, i.e., new visual system. Specifically, an agent trained
  on one set of environments (scenes) and with one particular visual recognition system
  is able to ask intelligent questions about new scenes when paired with a new visual
  recognition system. Trained on a synthetic dataset, our results show that our agent
  learns new visual concepts significantly faster than several heuristic baselines
  – even when tested on synthetic environments with novel objects, as well as in a
  realistic environment.
keywords: " Visual Curiosity, Learn to Ask, Visual Recognition, Dialog"
layout: inproceedings
series: Proceedings of Machine Learning Research
id: yang18a
month: 0
tex_title: 'Visual Curiosity: Learning to Ask Questions to Learn Visual Recognition'
firstpage: 63
lastpage: 80
page: 63-80
order: 63
cycles: false
bibtex_author: Yang, Jianwei and Lu, Jiasen and Lee, Stefan and Batra, Dhruv and Parikh,
  Devi
author:
- given: Jianwei
  family: Yang
- given: Jiasen
  family: Lu
- given: Stefan
  family: Lee
- given: Dhruv
  family: Batra
- given: Devi
  family: Parikh
date: 2018-10-23
address: 
publisher: PMLR
container-title: Proceedings of The 2nd Conference on Robot Learning
volume: '87'
genre: inproceedings
issued:
  date-parts:
  - 2018
  - 10
  - 23
pdf: http://proceedings.mlr.press/v87/yang18a/yang18a.pdf
extras:
- label: Source code
  link: https://github.com/jwyang/visual_curiosity
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
